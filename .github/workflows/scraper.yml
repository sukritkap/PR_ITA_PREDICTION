name: Run IRCC Scraper Every 2 Days

on:
  schedule:
    - cron: '0 0 */2 * *'  # Runs every 2 days at 00:00 UTC
  workflow_dispatch:       # Allows manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install selenium pandas beautifulsoup4

    - name: Set up Chrome
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable

    - name: Run scraper
      run: |
        sudo apt-get update
        sudo apt-get install -y unzip xvfb
        export DISPLAY=:99
        Xvfb :99 &

        python scraper.py

    - name: Commit and Push CSV if Changed
      env:
        GH_PAT: ${{ secrets.GH_PAT }}
      run: |
        git config --global user.email "github-actions@github.com"
        git config --global user.name "GitHub Actions"
        git add ircc_draw_history.csv
        git diff --cached --quiet || git commit -m "ðŸ”„ Auto-update IRCC draw data"

        git remote set-url origin https://x-access-token:${GH_PAT}@github.com/${{ github.repository }}
        git push origin HEAD:main 
